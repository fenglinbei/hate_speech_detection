{
  "output_name": "no-rag-1-vllm-724.json",
  "log": {
    "level": "INFO",
    "show_console": true
  },
   "model": {
    "type": "ApiLLMModel",
    "params": {
      "model_name": "llamafactory-2ep",
      "api_base": "http://127.0.0.1:35000/v1/",
      "api_key": "EMPTY",
      "temperature": 0.1, 
      "top_p": 0.8
    }
  },
  "tester": {
    "use_cache": true,
    "shot_dataset_file": "data/full/std/train.json",
    "test_dataset_file": "data/full/std/test.json",
    "shot_num": 0,
    "max_retries": 50,
    "concurrency": 5,
    "compute_metric": true,
    "prompt_templates": {
      "system": "",
      "train": "RAG_PROMPT_USER_V3",
      "shot": "",
      "example": ""
    },
    "parallel_num": 1,
    "per_parallel_attempts_num": 1,
    "run": {
      "shots_list": [0],
      "llm_params": {
         "max_new_tokens": 512, 
         "n": 1,
         "top_p": 0.8,
         "top_k": 20,
         "min_p": 0,
         "temperature": 0.1, 
         "enable_thinking": false
        }
    }
  }
}